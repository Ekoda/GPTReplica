{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.model import GPT\n",
    "from src.utils.data_utils import load_config, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,    11],\n",
      "       dtype=torch.int32)\n",
      "tensor([   30,   198,   198, 28934,  8895,    46,    25,   198, 10248,  2146],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.fromfile('../data/tokens/train_tokens.bin', np.uint16)\n",
    "val_data = np.fromfile('../data/tokens/val_tokens.bin', np.uint16)\n",
    "train_data = torch.from_numpy(train_data.astype(np.int32))\n",
    "val_data = torch.from_numpy(val_data.astype(np.int32))\n",
    "\n",
    "print(train_data[:10])\n",
    "print(val_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../config.yaml')\n",
    "\n",
    "slice_size = 0.1\n",
    "train_slice = train_data[:int(len(train_data) * slice_size)]\n",
    "val_slice = val_data[:int(len(val_data) * slice_size)]\n",
    "\n",
    "train_dataloader = load_data(train_data, config)\n",
    "val_dataloader = load_data(val_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Hardware:\n",
      "\tDevice: cuda\n",
      "\n",
      "Data\n",
      "\tTokenizer: gpt2\n",
      "\tTrain / Validation ratio: 0.9\n",
      "\n",
      "Model:\n",
      "\tModel dimensions: 512\n",
      "\tNumber of layers: 4\n",
      "\tNumber of attention heads: 8\n",
      "\tVocabulary size: 50257\n",
      "\tTotal trainable parameters: 62275665\n",
      "\n",
      "Training:\n",
      "\tBatch size: 16\n",
      "\tSequence length: 512\n",
      "\tNumber of training epochs: 1\n",
      "\tLearning rate: 0.0006\n",
      "\tOptimizer: AdamW\n",
      "\tLoss function: CrossEntropyLoss\n",
      "\tWeight decay: 0.1\n",
      "\tDropout rate: 0\n",
      "\tGradient clipping: 1.0\n",
      "\n",
      "Loaded parameters from: ../params/512.pth\n",
      "Model parameters will be saved at: ../params/512.pth\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPT(config)\n",
    "model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "\tTrain Loss: 0.6782918781847567\n",
      "\tVal Loss: 9.067201232910156\n",
      "\tTime: 10.471s\n"
     ]
    }
   ],
   "source": [
    "model.train_model(train_dataloader, val_dataloader, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
